{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1tO13aN1nnJqupL-JkydxBg7H5ET4y0HM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bvQPubCZ7JQ",
        "outputId": "ac12b895-ed99-48d3-9d5e-ac423f94c20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tO13aN1nnJqupL-JkydxBg7H5ET4y0HM\n",
            "To: /content/yelp_reviews_gen.csv\n",
            "100% 4.67G/4.67G [00:32<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAOu12P9K4lg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cuda if present\n",
        "device = torch.device(\"cuda\")\n",
        "print(\"Device available for running: \",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtDGmCXeNex-",
        "outputId": "1c9de4f9-c8b9-4804-f8e5-6050f8ffda95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available for running:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_CSV_PATH = './yelp_reviews_gen.csv'\n",
        "OUTPUT_FOLDER = './OpData'\n",
        "top_data_df = pd.read_csv(DATASET_CSV_PATH)"
      ],
      "metadata": {
        "id": "U3me9HZBOg9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map stars to sentiment\n",
        "def map_sentiment(stars_received):\n",
        "    if stars_received <= 3:\n",
        "        return -1\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Mapping stars to sentiment into three categories\n",
        "top_data_df['sentiment'] = [ map_sentiment(x) for x in top_data_df['stars']]"
      ],
      "metadata": {
        "id": "I9YaVCz_PMC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve top few number of each category\n",
        "def get_top_data(top_n = 5000):\n",
        "    top_data_df_positive = top_data_df[top_data_df['sentiment'] == 1].head(top_n)\n",
        "    # top_data_df_negative = top_data_df[top_data_df['sentiment'] == -1].head(top_n)\n",
        "    top_data_df_neutral = top_data_df[top_data_df['sentiment'] == -1].head(top_n)\n",
        "    top_data_df_small = pd.concat([top_data_df_positive, top_data_df_neutral])\n",
        "    return top_data_df_small\n",
        "\n",
        "# Function call to get the top 10000 from each sentiment\n",
        "top_data_df_small = get_top_data(top_n=10000)"
      ],
      "metadata": {
        "id": "gmOFdKA8PzpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Preprocessing of data\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "\n",
        "# Tokenize the text column to get the new column 'tokenized_text'\n",
        "top_data_df_small['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in top_data_df_small['text']] \n",
        "\n",
        "# Get the stemmed_tokens\n",
        "porter_stemmer = PorterStemmer()\n",
        "top_data_df_small['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in top_data_df_small['tokenized_text'] ]\n"
      ],
      "metadata": {
        "id": "MjT48lsDQNwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into Train and Test Sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train Test Split Function\n",
        "def split_train_test(top_data_df_small, test_size=0.3, shuffle_state=True):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(top_data_df_small[['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text', 'useful', 'user_id', 'stemmed_tokens']], \n",
        "                                                        top_data_df_small['sentiment'], \n",
        "                                                        shuffle=shuffle_state,\n",
        "                                                        test_size=test_size, \n",
        "                                                        random_state=15)\n",
        "    print(\"Value counts for Train sentiments\")\n",
        "    print(Y_train.value_counts())\n",
        "    print(\"Value counts for Test sentiments\")\n",
        "    print(Y_test.value_counts())\n",
        "    print(type(X_train))\n",
        "    print(type(Y_train))\n",
        "    X_train = X_train.reset_index()\n",
        "    X_test = X_test.reset_index()\n",
        "    Y_train = Y_train.to_frame()\n",
        "    Y_train = Y_train.reset_index()\n",
        "    Y_test = Y_test.to_frame()\n",
        "    Y_test = Y_test.reset_index()\n",
        "    print(X_train.head())\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "# Call the train_test_split\n",
        "X_train, X_test, Y_train, Y_test = split_train_test(top_data_df_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hthzG5RROSf",
        "outputId": "8fe5304d-bf86-40bd-bc52-b5804286557d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for Train sentiments\n",
            " 1    7005\n",
            "-1    6995\n",
            "Name: sentiment, dtype: int64\n",
            "Value counts for Test sentiments\n",
            "-1    3005\n",
            " 1    2995\n",
            "Name: sentiment, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "   index             business_id  cool                 date  funny  \\\n",
            "0  22876  _cndcbuaqSRW5f-MeZasNw   0.0  2016-05-20 18:52:45    0.0   \n",
            "1  20123  uFF40n9pOqHK1ciajdoSEw   1.0  2011-07-01 03:44:45    0.0   \n",
            "2  18063  YisnHfR8rvlYFNtauQF14w   0.0  2016-08-05 12:21:51    0.0   \n",
            "3    546  4WdDY97x4GdMYtyk1KQMnw   0.0  2013-11-14 01:20:24    1.0   \n",
            "4   6079  6ZUERrfjvr7HGOB6uwFLZQ   0.0  2013-10-24 11:07:55    0.0   \n",
            "\n",
            "                review_id  stars  \\\n",
            "0  S1AEveqyNQ7upnoKe6R4Mw    1.0   \n",
            "1  2K-CXKsz8vFzAEQBQ6e9lw    3.0   \n",
            "2  c_Iy6yFpJzQqCsYb5IX-rw    3.0   \n",
            "3  abKghvZEZue9xTHBRpZFAw    4.0   \n",
            "4  HZP700rUc8OdapSAZMBrdA    2.0   \n",
            "\n",
            "                                                text  useful  \\\n",
            "0  Came here last week for my wife and  I's 3rd w...     1.0   \n",
            "1  Food is ok. They had good Italian sandwiches. ...     1.0   \n",
            "2  Ate there last night with the family. They did...     1.0   \n",
            "3  Again for those that see my review I only give...     1.0   \n",
            "4  This hotel was gross. There was a stinky cigar...     0.0   \n",
            "\n",
            "                  user_id                                     stemmed_tokens  \n",
            "0  7GVfxscSxsJ9E6IsEzh1bQ  [came, here, last, week, for, my, wife, and, r...  \n",
            "1  DvWM62NWf2MV1EpN7T8S1A  [food, is, ok, thei, had, good, italian, sandw...  \n",
            "2  iG45KccScyqvhKvC74TBNg  [at, there, last, night, with, the, famili, th...  \n",
            "3  mLtqw04f9aYwz35NPU2j3Q  [again, for, those, that, see, my, review, onl...  \n",
            "4  37pz7BP6RUn8dV5Cv4PoWA  [thi, hotel, wa, gross, there, wa, stinki, cig...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "size = 500\n",
        "window = 3\n",
        "min_count = 1\n",
        "workers = 3\n",
        "sg = 1\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Function to train word2vec model\n",
        "def make_word2vec_model(top_data_df_small, padding=True, sg=1, min_count=1, size=500, workers=3, window=3):\n",
        "    if  padding:\n",
        "        print(len(top_data_df_small))\n",
        "        temp_df = pd.Series(top_data_df_small['stemmed_tokens']).values\n",
        "        temp_df = list(temp_df)\n",
        "        temp_df.append(['pad'])\n",
        "        word2vec_file = OUTPUT_FOLDER + '/models/'+'word2vec_' + str(size) + '_PAD.model'\n",
        "    else:\n",
        "        temp_df = top_data_df_small['stemmed_tokens']\n",
        "        word2vec_file = OUTPUT_FOLDER + '/models/' + 'word2vec_' + str(size) + '.model'\n",
        "    w2v_model = Word2Vec(temp_df, min_count = min_count, vector_size=size, workers = workers, window = window, sg = sg)\n",
        "\n",
        "    w2v_model.save(word2vec_file)\n",
        "    return w2v_model, word2vec_file\n",
        "\n",
        "# Train Word2vec model\n",
        "w2vmodel, word2vec_file = make_word2vec_model(top_data_df_small, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiSn05GrTnp_",
        "outputId": "6c8eaac8-ae4c-400e-976a-b806c672b76c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sen_len = top_data_df_small.stemmed_tokens.map(len).max()\n",
        "padding_idx = w2vmodel.wv.key_to_index['pad']\n",
        "def make_word2vec_vector_lstm(sentence):\n",
        "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
        "    i = 0\n",
        "    for word in sentence:\n",
        "        if word not in w2vmodel.wv.key_to_index:\n",
        "            padded_X[i] = 0\n",
        "            print(word)\n",
        "        else:\n",
        "            padded_X[i] = w2vmodel.wv.key_to_index[word]\n",
        "        i += 1\n",
        "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
      ],
      "metadata": {
        "id": "kod2MRP5efMN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the output tensor\n",
        "def make_target(label):\n",
        "    if label == 0:\n",
        "        return torch.tensor([0], dtype=torch.long, device=device)\n",
        "    else:\n",
        "        return torch.tensor([1], dtype=torch.long, device=device)"
      ],
      "metadata": {
        "id": "-QcRSve832wI"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "class SentimentAnalysisLSTM(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout) :\n",
        "        super().__init__()\n",
        "\n",
        "        w2vmodel = gensim.models.KeyedVectors.load(OUTPUT_FOLDER + '/models/' + 'word2vec_500_PAD.model')\n",
        "        weights = w2vmodel.wv\n",
        "\n",
        "        # The embedding layer takes the vocab size and the embeddings size as input\n",
        "        # self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        # Pretrained embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=w2vmodel.wv.key_to_index['pad'])\n",
        "\n",
        "        # The LSTM layer takes in the the embedding size and the hidden vector size.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # We use dropout before the final layer to improve with regularization\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "        # The fully-connected layer takes in the hidden dim of the LSTM and\n",
        "        #  outputs a a 3x1 vector of the class scores.\n",
        "        self.fc = nn.Linear(hidden_dim, NUM_CLASSES) \n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # The input is transformed to embeddings by passing it to the embedding layer\n",
        "        embs = self.embedding(x)\n",
        "\n",
        "        # The embedded inputs are fed to the LSTM alongside the previous hidden state\n",
        "        out, hidden = self.lstm(embs, hidden)\n",
        "\n",
        "        # Dropout is applied to the output and fed to the FC layer\n",
        "        # out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.relu(out)\n",
        "        # We extract the scores for the final hidden state since it is the one that matters.\n",
        "        out = out[:, -1]\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, 32), torch.zeros(1, 1, 32))"
      ],
      "metadata": {
        "id": "DW3cYUr4dZYS"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(w2vmodel.wv)\n",
        "\n",
        "lstm_model = SentimentAnalysisLSTM(vocab_size=vocab_len, embedding_dim = 500, hidden_dim = 32, dropout=0.3)\n",
        "lstm_model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "\n",
        "# Open the file for writing loss\n",
        "loss_file_name = OUTPUT_FOLDER +  '/plots/' + 'lstm3_class_big_loss_with_padding.csv'\n",
        "f = open(loss_file_name,'w')\n",
        "f.write('iter, loss')\n",
        "f.write('\\n')\n",
        "losses = []\n",
        "lstm_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch\" + str(epoch + 1))\n",
        "    train_loss = 0\n",
        "    h0, c0 =  lstm_model.init_hidden()\n",
        "\n",
        "    h0 = h0.to(device)\n",
        "    c0 = c0.to(device)\n",
        "    for index, row in X_train.iterrows():\n",
        "        # input = row[0].to(device)\n",
        "        # target = row[1].to(device)\n",
        "\n",
        "        # Make the bag of words vector for stemmed tokens \n",
        "        input = make_word2vec_vector_lstm(row['stemmed_tokens'])\n",
        "        # Get the target label\n",
        "        target = make_target(Y_train['sentiment'][index])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            out, hidden = lstm_model(input, (h0, c0))\n",
        "            loss = loss_function(out, target)\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "\n",
        "    # if index == 0:\n",
        "    #     continue\n",
        "    print(\"Epoch ran :\"+ str(epoch+1))\n",
        "    f.write(str((epoch+1)) + \",\" + str(train_loss / len(X_train)))\n",
        "    f.write('\\n')\n",
        "    train_loss = 0\n",
        "\n",
        "torch.save(lstm_model, OUTPUT_FOLDER +'/'+'lstm3_big_model_500_with_padding.pth')\n",
        "\n",
        "f.close()\n",
        "print(\"Input vector\")\n",
        "print(input.cpu().numpy())\n",
        "print(\"Output vector\")\n",
        "print(out)\n",
        "print(torch.argmax(out, dim=1).cpu().numpy()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVtjS2Ma7SSl",
        "outputId": "fbbfe5aa-0391-4e6d-aa7e-bb56b9b6f97a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1\n",
            "Epoch ran :1\n",
            "Epoch2\n",
            "Epoch ran :2\n",
            "Epoch3\n",
            "Epoch ran :3\n",
            "Epoch4\n",
            "Epoch ran :4\n",
            "Epoch5\n",
            "Epoch ran :5\n",
            "Epoch6\n",
            "Epoch ran :6\n",
            "Epoch7\n",
            "Epoch ran :7\n",
            "Epoch8\n",
            "Epoch ran :8\n",
            "Epoch9\n",
            "Epoch ran :9\n",
            "Epoch10\n",
            "Epoch ran :10\n",
            "Input vector\n",
            "[[  247    43   251   180     0    33     2   170    46   345   746     1\n",
            "  12685   107   273    60     2  1729   107   270     2   841    36   662\n",
            "     32  2259  1619   203     1   265     3   178    48     0  1749   128\n",
            "     32     0   178   968   243    15   261     1   490   467  1231     0\n",
            "     34    22     0    78     7   210    30  5093  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149  1149\n",
            "   1149  1149  1149]]\n",
            "Output vector\n",
            "tensor([[ 0.0000, 16.6437]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "bow_lstm_predictions = []\n",
        "original_lables_cnn_bow = []\n",
        "lstm_model.eval()\n",
        "loss_df = pd.read_csv(OUTPUT_FOLDER + '/plots/'+'lstm3_class_big_loss_with_padding.csv')\n",
        "print(loss_df.columns)\n",
        "# loss_df.plot('loss')\n",
        "with torch.no_grad():\n",
        "    for index, row in X_test.iterrows():\n",
        "        bow_vec = make_word2vec_vector_lstm(row['stemmed_tokens'])\n",
        "        probs, hidden = lstm_model(bow_vec, (h0, c0))\n",
        "        _, predicted = torch.max(probs.data, 1)\n",
        "        bow_lstm_predictions.append(predicted.cpu().numpy()[0])\n",
        "        original_lables_cnn_bow.append(make_target(Y_test['sentiment'][index]).cpu().numpy()[0])\n",
        "print(classification_report(original_lables_cnn_bow,bow_lstm_predictions))\n",
        "loss_file_name = OUTPUT_FOLDER +  '/plots/' + 'lstm3_class_big_loss_with_padding.csv'\n",
        "loss_df = pd.read_csv(loss_file_name)\n",
        "print(loss_df.columns)\n",
        "plt_500_padding_30_epochs = loss_df[' loss'].plot()\n",
        "fig = plt_500_padding_30_epochs.get_figure()\n",
        "fig.savefig(OUTPUT_FOLDER +'/plots/' + 'loss_plt_500_padding_30_epochs.pdf')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "fsoxP2ej9NzU",
        "outputId": "fa34fc6f-a5c3-40fe-82f5-0da12531d95c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['iter', ' loss'], dtype='object')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      6000\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "Index(['iter', ' loss'], dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}